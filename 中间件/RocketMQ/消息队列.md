消息队列



1. 为什么使用[消息队列](https://blog.csdn.net/alinshen/article/details/80583214)？
2. 使用消息队列有什么缺点?
3. [消息队列](https://blog.csdn.net/alinshen/article/details/80583214)如何选型?
4. 如何保证消息队列是高可用的？
5. 如何保证消息不被重复消费?
6. 如何保证消费的可靠性传输?
7. 如何保证消息的顺序性？



### 1、为什么要使用消息队列?

解耦、异步、削峰

#### (1)解耦

传统模式:

![image-20201002220615942](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002220616.png)

传统模式的缺点：

- 系统间耦合性太强，如上图所示，系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！

中间件模式:

![image-20201002220752038](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002220752.png)

中间件模式的的优点：

- 将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。

#### (2)异步

传统模式:

![image-20201002220827630](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002220827.png)

传统模式的缺点：

- 一些非必要的业务逻辑以同步的方式运行，太耗费时间。

中间件模式:

![image-20201002220852681](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002220852.png)

中间件模式的的优点：

- 将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度

#### (3)削峰

传统模式

![image-20201002220913320](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002220913.png)

传统模式的缺点：

- 并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常

中间件模式:

![image-20201002221026422](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002221026.png)

中间件模式的的优点：

- 系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。

### 2、使用了消息队列会有什么缺点?

- 系统可用性降低:你想啊，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性降低
- 系统复杂性增加:要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输。因此，需要考虑的东西更多，系统复杂性增大。

### 3、消息队列如何选型?

| 特性       | ActiveMQ                                                     | RabbitMQ                                                     | RocketMQ                 | kafka                                                        |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------ | ------------------------------------------------------------ |
| 开发语言   | java                                                         | erlang                                                       | java                     | scala                                                        |
| 单机吞吐量 | 万级                                                         | 万级                                                         | 10万级                   | 10万级                                                       |
| 时效性     | ms级                                                         | us级                                                         | ms级                     | ms级以内                                                     |
| 可用性     | 高(主从架构)                                                 | 高(主从架构)                                                 | 非常高(分布式架构)       | 非常高(分布式架构)                                           |
| 功能特性   | 成熟的产品，在很多公司得到应用；有较多的文档；各种协议支持较好 | 基于erlang开发，所以并发能力很强，性能极其好，延时很低;管理界面较丰富 | MQ功能比较完备，扩展性佳 | 只支持主要的MQ功能，像一些消息查询，消息回溯等功能没有提供，毕竟是为大数据准备的，在大数据领域应用广。 |

(1)中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。
(2)大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，根据业务场景选择，如果有日志采集功能，肯定是首选kafka了。具体该选哪个，看使用场景。

### 4、如何保证消息队列是高可用的？

以rcoketMQ为例，他的集群就有多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。

![image-20201002224147694](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002224147.png)

Producer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。
那么kafka呢,为了对比说明直接上kafka的拓补架构图

![image-20201002225043303](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002225043.png)

如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。
至于rabbitMQ,也有普通集群和镜像集群模式，自行去了解，比较简单，两小时即懂。

### 5、如何保证消息不被重复消费？

分析:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。
回答:先来说一下为什么会造成重复消费?
  其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。
  如何解决?这个问题针对业务场景来答分以下几点
  (1)比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
  (2)再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。
  (3)如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。

### 6、如何保证消费的可靠性传输?

分析:我们在使用消息队列的过程中，应该做到消息不能多消费，也不能少消费。如果无法做到可靠性传输，可能给公司带来千万级别的财产损失。同样的，如果可靠性传输在使用过程中，没有考虑到，这不是给公司挖坑么，你可以拍拍屁股走了，公司损失的钱，谁承担。还是那句话，认真对待每一个项目，不要给公司挖坑。
回答:其实这个可靠性传输，每种MQ都要从三个角度来分析:生产者弄丢数据、消息队列弄丢数据、消费者弄丢数据

#### RabbitMQ

(1)生产者丢数据
从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。
transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。
然而缺点就是吞吐量下降了。因此，按照博主的经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。处理Ack和Nack的代码如下所示（说好不上代码的，偷偷上了）:

1.  

   channel.addConfirmListener(new ConfirmListener() {

2.  

   @Override

3.  

   public void handleNack(long deliveryTag, boolean multiple) throws IOException {

4.  

   System.out.println("nack: deliveryTag = "+deliveryTag+" multiple: "+multiple);

5.  

   }

6.  

   @Override

7.  

   public void handleAck(long deliveryTag, boolean multiple) throws IOException {

8.  

   System.out.println("ack: deliveryTag = "+deliveryTag+" multiple: "+multiple);

9.  

   }

10.  

    });

(2)消息队列丢数据
处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。
那么如何持久化呢，这里顺便说一下吧，其实也很容易，就下面两步
1、将queue的持久化标识durable设置为true,则代表是一个持久的队列
2、发送消息的时候将deliveryMode=2
这样设置以后，rabbitMQ就算挂了，重启后也能恢复数据
(3)消费者丢数据
消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。
至于解决方案，采用手动确认消息即可。



#### kafka

这里先引一张kafka Replication的数据流向图
![image-20201002225254457](https://gitee.com/fking86/images4typora/raw/master/imgs/20201002225254.png)
Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader中pull数据。
针对上述情况，得出如下分析
(1)生产者丢数据
在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置

1. 第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。
2. 在producer端设置retries=MAX，一旦写入失败，这无限重试

(2)消息队列丢数据
针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。

1. replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本
2. min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系

这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据

(3)消费者丢数据
这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的
offset：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。
比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49(offset从0开始)，那么下次消费的时候offset就从50开始消费。
解决方案也很简单，改成手动提交即可。



**RocketMQ**

​	作为一个消息中间件，RocketMQ的消息可靠性就是指确保消息数据不丢失。具体而言就是从消息在生产者产生，经过服务端投递，一定能被消费者消费。在`rocketMQ`中会返回消息发送状态码,**`rocketMQ`还提供了生产者事务操作**。
**消息生产者Producer消息发送有三种方式：同步，异步，单向(Oneway)**
1.同步发送 ，需要同时等待

```java
SendResult sendResult = producer.send(message);
```

2.异步发送，异步线程发送出去消息，速度快//重点在SendCallback这里 异步发送回调，可靠性在于需要根据返回结果在回调里面处理业务。

```java
producer.send(message, new SendCallback() {



           @Override



           public void onSuccess(SendResult sendResult) {



               System.out.printf(sendResult.getSendStatus()+"");



           }



 



           @Override



           public void onException(Throwable throwable) {



                    //根据业务处理



           }



       });
```

3.oneway  方式，只管发送，不在意是否成功，日志处理一般这样

```java
producer.sendOneway(msg);
```

4.事务消息，通过实现TransactionMQProducer，并且编写本地事务监听器。

TransactionCheckListener transactionCheckListener

```java
  @Override



    public TransactionSendResult sendMessageInTransaction(final Message msg,



                                                          final LocalTransactionExecuter tranExecuter, final Object arg) throws MQClientException {



        if (null == this.transactionCheckListener) {



            throw new MQClientException("localTransactionBranchCheckListener is null", null);



        }



 



        return this.defaultMQProducerImpl.sendMessageInTransaction(msg, tranExecuter, arg);



    }
```

关键点在于：
1.重试时Message Key必须保证唯一，因为重试原因不确定我们无法保证消息是否已经发生过一次，Message Key唯一能最大程度保证业务的一致性
2.日志的保存，关键字段，请求的操作人，时间，重试次数，请求体，返回结果(可以和请求体分开保存日志，避免请求中断带来的不确定性。

**Consumer保证消息可靠性** 

   consume分为集群模式和广播模式，消费者获取消息的方式又分为PUSH模式和PULL模式。首先广播模式下每个consumer在本地管理消息，所以如何保证消息被正确消费，消费失败如何处理都需要开发者自己关注。如果是PULL模式，那么消息如何消费都是有开发者自己定义的。所以这都不是我们考虑的重点。消费者Consumer消费消息可靠性更多的是在讨论集群模式下PUSH方式消息的可靠性。

**1.重试队列**
Consumer端因为各种类型异常导致消费失败，为防止消息丢失而需要将其重新回发给Broker端消息队列保存，称之为重试队列。RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列，用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULE_TOPIC_XXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中
**2,.死信队列**
由于有些原因导致Consumer端长时间的无法正常消费从Broker端Pull过来的业务消息，为了确保消息不会被无故的丢弃，那么超过配置的“最大重试消费次数”后就会移入到这个死信队列中。在RocketMQ中，SubscriptionGroupConfig配置常量默认地设置了两个参数，一个是retryQueueNums为1（重试队列数量为1个），另外一个是retryMaxTimes为16。Broker端通过校验判断，如果超过了最大重试消费次数则会将消息移至这里所说的死信队列。这里，RocketMQ会为每个消费组都设置一个Topic命名为“%DLQ%+consumerGroup"的死信队列。一般在实际应用中，移入至死信队列的消息，需要人工干预处理。

**Broker端保证消息可靠性**

Broker端的消息可靠性保证更多的要从架构层次来说明。常见的架构策略：

双主双从架构，NameServer多节点，同步双写，异步刷盘，消息在内存中，突然断电消息丢失，同步刷盘可靠性更高，消息持续化到磁盘，同城双活，异地多活，跨国多活



**ActiveMQ**



# 7、如何保证消息的顺序性？

回答:针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。



RocketMQ

## 1.实现顺序消费

    RocketMQ支持局部顺序消费，但不支持全局，换句话说针对Topic中的每个queue是可以按照FIFO进行消费。
    要保证一个订单有关的消息顺序消费，有两点需要注意，一是将订单有关的消息发送到相关Topic中同一个queue里，二是消费者按照先进先出的原则进行消费。

## 2.消息发送到指定queue中

    在消息发送时，需指定对应的MessageQueueSelector，此时我们只需通过订单号与queue进行关联，代码如下。send中的参数arg即为select中的arg，将订单号作为参数传入，同一订单号的相关消息则可以保证在同一queue中。

```java
send(Message msg, MessageQueueSelector selector, Object arg)
1
private MessageQueueSelector messageQueueSelector = new MessageQueueSelector() {
        @Override
        public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
            try {
                int id = arg.hashCode();
                int index = Math.abs(id) % mqs.size();
                return mqs.get(index);
            } catch (Exception e) {
                log.error("MessageQueueSelector issue: " + e.getClass().getName() + " " + e.getLocalizedMessage());
                return mqs.get(0);
            }
        }
    };
12345678910111213
```

## 3.顺序消费

    如果使用MessageListenerConcurrently的话，必须保证是单线程才能顺序消费，但生产环境下，我们一般 都是多线程的形成，这样则需要使用MessageListenerOrderly。

```java
consumer.setConsumeThreadMin(1);
consumer.setConsumeThreadMax(1);
...
consumer.registerMessageListener(
                new MessageListenerConcurrently() {
                    @Override
                    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
                    ...
         			}
        		});
12345678910
```

    MessageListenerOrderly使用代码如下。

```java
consumer.setConsumeThreadMin(4);
consumer.setConsumeThreadMax(8);
consumer.registerMessageListener(
        		new MessageListenerOrderly() {
					@Override
					public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, ConsumeOrderlyContext context) {
						
					...
					}
				});
```



但是这样的话会有以下问题：

1、遇到消息失败的消息，无法跳过，当前队列消费暂停 

2、目前版本的RocketMQ的MessageListenerOrderly是不能从slave消费消息的。



有的人会问:那如果为了吞吐量，有多个消费者去消费怎么办？
这个问题，没有固定回答的套路。比如我们有一个微博的操作，发微博、写评论、删除微博，这三个异步操作。如果是这样一个业务场景，那只要重试就行。比如你一个消费者先执行了写评论的操作，但是这时候，微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行写评论的操作后，再执行，就可以成功。
总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。